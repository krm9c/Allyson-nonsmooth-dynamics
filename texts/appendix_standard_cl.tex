\section{CL Implementation \& Condition Details}
\label{app:standard_cl}

This appendix provides implementation details for the four experimental conditions (C1--C4) used in this paper. All algorithms use the notation from the main text: $\weight(t)$ denotes weights at task $t$, $\psi(t)$ denotes architecture, $\tx(t)$ denotes task data, $\fhat(\weight,\psi)$ denotes the neural network, and $\mathcal{E}$ denotes the experience replay buffer.


%=======This is Appendix J=======%
\subsection{Experimental Conditions Overview \& Algorithm}

Figure~\ref{fig:alg_conditions} presents the four experimental conditions as a unified algorithmic framework. Each condition builds upon the previous one:
\begin{itemize}
    \item \textbf{C1 (Baseline)}: Fixed architecture, constant learning rate, no warmup
    \item \textbf{C2 (Heuristics)}: Adds task warmup, cosine LR schedule, adaptive gradient weights
    \item \textbf{C3 (Arch Search)}: Adds architecture search at task boundaries with random reinitialization
    \item \textbf{C4 (AWB Full)}: Adds knowledge transfer via $A$, $B$ matrices instead of random reinitialization
\end{itemize}

\begin{figure}[!htb]
\centering

% Panel (a) - C1 Baseline
\begin{minipage}[t]{0.48\textwidth}
\begin{algorithm}[H]
\caption*{\textbf{(a) C1: Baseline}}
\label{alg:c1}
\KwIn{$\weight(0), \psi_0, \{\tx(t)\}_{t=0}^T$}
\KwOut{$\weight(T)$}
\textbf{Init:} $\eta = 10^{-4}$, $[\alpha,\beta,\gamma] = [0.4, 0.4, 0.1]$\;
\For{$t = 0$ \KwTo $T$}{
    \For{$e = 1$ \KwTo $N_{\text{epochs}}$}{
        $\mathcal{B}_c \gets$ \texttt{sample}$(\tx(t))$\;
        $\mathcal{B}_e \gets$ \texttt{sample}$(\mathcal{E})$\;
        $\nabla H \gets$ \textsc{HamGrad}$(\weight, \mathcal{B}_c, \mathcal{B}_e)$\;
        $\weight \gets \weight - \eta \cdot \nabla H$\;
    }
    $\mathcal{E} \gets \mathcal{E} \cup \tx(t)$\;
}
\textbf{Return} $\weight$\;
\end{algorithm}
\vspace{0.3em}
{\footnotesize \textit{Fixed $\psi_0$, constant $\eta$, no warmup.}}
\end{minipage}
\hfill
% Panel (b) - C2 Heuristics
\begin{minipage}[t]{0.48\textwidth}
\begin{algorithm}[H]
\caption*{\textbf{(b) C2: Heuristics}}
\label{alg:c2}
\KwIn{$\weight(0), \psi_0, \{\tx(t)\}_{t=0}^T$}
\KwOut{$\weight(T)$}
\textbf{Init:} $\eta_0 = 10^{-4}$, $[\alpha,\beta,\gamma] = [0.4, 0.4, 0.1]$\;
\For{$t = 0$ \KwTo $T$}{
    \If{$t > 0$}{
        $\weight \gets$ \textsc{Warmup}$(\weight, \tx(t))$ \tcp*[f]{Alg.~\ref{alg:warmup}}\;
        $[\alpha,\beta,\gamma] \gets$ \textsc{AdaptGrad}$(J_t, J_{t-1})$ \tcp*[f]{Alg.~\ref{alg:adaptive}}\;
    }
    \For{$e = 1$ \KwTo $N_{\text{epochs}}$}{
        $\mathcal{B}_c, \mathcal{B}_e \gets$ \texttt{sample}$(\tx(t)), $ \textsc{BalReplay}$(\mathcal{E})$\;
        $\nabla H \gets$ \textsc{HamGrad}$(\weight, \mathcal{B}_c, \mathcal{B}_e)$\;
        $\eta \gets$ \textsc{CosineDecay}$(\eta_0, e)$\;
        $\weight \gets \weight - \eta \cdot \nabla H$\;
    }
    $\mathcal{E} \gets \mathcal{E} \cup \tx(t)$\;
}
\textbf{Return} $\weight$\;
\end{algorithm}
\vspace{0.3em}
{\footnotesize \textit{Fixed $\psi_0$, adds warmup + cosine LR + adaptive gradients.}}
\end{minipage}

\vspace{1em}

% Panel (c) - C3 Arch Search
\begin{minipage}[t]{0.48\textwidth}
\begin{algorithm}[H]
\caption*{\textbf{(c) C3: Architecture Search}}
\label{alg:c3}
\KwIn{$\weight(0), \psi(0), \{\tx(t)\}_{t=0}^T$}
\KwOut{$\weight(T), \psi(T)$}
\textbf{Init:} As C2\;
\For{$t = 0$ \KwTo $T$}{
    \If{$t > 0$}{
        $\weight \gets$ \textsc{Warmup}$(\weight, \tx(t))$\;
        $[\alpha,\beta,\gamma] \gets$ \textsc{AdaptGrad}$(J_t, J_{t-1})$\;
        \If{\textsc{ShouldChange}$(J_t, J_{t-1})$}{
            $\psi^* \gets$ \textsc{ArchSearch}$(\psi, \tx(t))$ \tcp*[f]{Alg.~\ref{alg:arch_search}}\;
            $\weight \gets$ \textsc{GlorotInit}$(\psi^*)$ \tcp*[f]{Random reinit}\;
            $\psi \gets \psi^*$\;
        }
    }
    \For{$e = 1$ \KwTo $N_{\text{epochs}}$}{
        \tcp{Same training loop as C2}
        $\nabla H \gets$ \textsc{HamGrad}$(\weight, \mathcal{B}_c, \mathcal{B}_e)$\;
        $\weight \gets \weight - \eta \cdot \nabla H$\;
    }
    $\mathcal{E} \gets \mathcal{E} \cup \tx(t)$\;
}
\textbf{Return} $\weight, \psi$\;
\end{algorithm}
\vspace{0.3em}
{\footnotesize \textit{Adaptive $\psi(t)$, random reinit after arch change.}}
\end{minipage}
\hfill
% Panel (d) - C4 AWB Full
\begin{minipage}[t]{0.48\textwidth}
\begin{algorithm}[H]
\caption*{\textbf{(d) C4: AWB Full}}
\label{alg:c4}
\KwIn{$\weight(0), \psi(0), \{\tx(t)\}_{t=0}^T$}
\KwOut{$\weight(T), \psi(T)$}
\textbf{Init:} As C2\;
\For{$t = 0$ \KwTo $T$}{
    \If{$t > 0$}{
        $\weight \gets$ \textsc{Warmup}$(\weight, \tx(t))$\;
        $[\alpha,\beta,\gamma] \gets$ \textsc{AdaptGrad}$(J_t, J_{t-1})$\;
        \If{\textsc{ShouldChange}$(J_t, J_{t-1})$}{
            $\psi^* \gets$ \textsc{ArchSearch}$(\psi, \tx(t))$\;
            $A, B \gets$ \textsc{TrainAB}$(\weight, \psi, \psi^*, \tx(t))$ \tcp*[f]{Alg.~\ref{alg:train_ab}}\;
            $\weight \gets A \cdot \weight \cdot B^T$ \tcp*[f]{AWB transfer}\;
            $\psi \gets \psi^*$\;
        }
    }
    \For{$e = 1$ \KwTo $N_{\text{epochs}}$}{
        \tcp{Same training loop as C2}
        $\nabla H \gets$ \textsc{HamGrad}$(\weight, \mathcal{B}_c, \mathcal{B}_e)$\;
        $\weight \gets \weight - \eta \cdot \nabla H$\;
    }
    $\mathcal{E} \gets \mathcal{E} \cup \tx(t)$\;
}
\textbf{Return} $\weight, \psi$\;
\end{algorithm}
\vspace{0.3em}
{\footnotesize \textit{Adaptive $\psi(t)$, knowledge transfer via $V = A\weight B^T$.}}
\end{minipage}

\caption{Four experimental conditions for Hamiltonian Continual Learning. (a) C1 uses fixed architecture and constant hyperparameters. (b) C2 adds heuristics: task warmup, cosine LR decay, and adaptive gradient weights. (c) C3 adds architecture search with random reinitialization. (d) C4 replaces random reinitialization with AWB transfer to preserve learned knowledge.}
\label{fig:alg_conditions}
\end{figure}



\subsection{Supporting Algorithms to Figure~\ref{fig:alg_conditions}}
The algorithms below are those referenced in Figure~\ref{fig:alg_conditions}.

\textbf{Task Warm-up}

{\small
\begin{algorithm}[H]
\caption{Task Warmup}\label{alg:warmup}
\KwIn{$\weight, \tx(t)$}
\KwOut{$\weight$}
$\eta_w \gets 0.1 \cdot \eta_0$, $[\alpha,\beta,\gamma] \gets [1, 0, 0]$\;
\For{$e = 1$ \KwTo $N_{\text{warmup}}$}{
    $\mathcal{B} \gets$ \texttt{sample}$(\tx(t))$\;
    $\weight \gets \weight - \eta_w \cdot \nabla_\weight \ell(\fhat(\weight), \mathcal{B})$\; }
\text{\textbf{Return}} $\weight$ \;
\end{algorithm}
}

\textbf{Adaptive Gradient Weights}

{\small
\begin{algorithm}[H]
\caption{Adaptive Gradient Weights}\label{alg:adaptive}
\KwIn{$J_{\text{curr}}, J_{\text{prev}}$}
\KwOut{$[\alpha, \beta, \gamma]$}
$r \gets J_{\text{curr}} / J_{\text{prev}}$\;
$\alpha \gets \min(0.7, 0.3 + 0.4 \cdot (r - 1))$ \tcp*[f]{Increase current task weight if loss ratio high}\;
$\beta \gets \max(0.2, 0.6 - 0.4 \cdot (r - 1))$ \tcp*[f]{Decrease experience weight}\;
$\gamma \gets 0.1$\;
\textbf{Return} $[\alpha, \beta, \gamma]$\;
\end{algorithm}
}

\textbf{Architecture Search}

{\small
\begin{algorithm}[H]
\caption{NDDS Architecture Search}\label{alg:arch_search}
\KwIn{$\psi, \tx(t)$}
\KwOut{$\psi^*$}
$\{d_1, \ldots, d_L\} \gets$ \texttt{extract\_dims}$(\psi)$\;
$\mathcal{S} \gets \{d_i \pm k \cdot 16 : i \in [L], k \in \{1,2,3\}\}$\;
$\psi^* \gets \arg\min_{\psi' \in \mathcal{S}} J(\texttt{init}(\psi'), \psi', \tx_{\text{val}})$\;
\textbf{Return} $\psi^*$\;
\end{algorithm}
}

\textbf{Train A/B Matrices}

{\small
\begin{algorithm}[H]
\caption{Train A/B Matrices (W Frozen)}\label{alg:train_ab}
\KwIn{Frozen $\weight$, $\psi_{\text{old}}, \psi_{\text{new}}, \tx(t)$}
\KwOut{$A, B$}
$A \gets I_{m \times n}$, $B \gets I_{p \times q}$ where dims match $\psi_{\text{old}} \to \psi_{\text{new}}$\;
\For{$e = 1$ \KwTo $N_{\text{AB}}$}{
    $\mathcal{B} \gets$ \texttt{sample}$(\tx(t))$\;
    $V \gets A \cdot \weight \cdot B^T$\;
    $\nabla_{A,B} \gets \nabla_{A,B} \ell(\fhat(V, \psi_{\text{new}}), \mathcal{B})$\;
    $A, B \gets$ \texttt{optimizer\_step}$(A, B, \nabla_{A,B})$\;
}
\textbf{Return} $A, B$\;
\end{algorithm}
}

\textbf{Hamiltonian Gradient}

{\small
\begin{algorithm}[H]
\caption{Hamiltonian Gradient}\label{alg:hamiltonian}
\KwIn{$\weight, \psi, \mathcal{B}_{\text{curr}}, \mathcal{B}_{\text{exp}}, [\alpha, \beta, \gamma]$}
\KwOut{$\nabla_{\weight} H$}
$\nabla_c \gets \nabla_{\weight} \ell(\fhat(\weight, \psi), \mathcal{B}_{\text{curr}})$ \tcp*[f]{Current task gradient}\;
$\nabla_e \gets \nabla_{\weight} \ell(\fhat(\weight, \psi), \mathcal{B}_{\text{exp}})$ \tcp*[f]{Experience gradient}\;
$\delta V \gets$ \textsc{PerturbationGrad}$(\weight, \psi, \mathcal{B}_{\text{exp}})$ \tcp*[f]{Regularization}\;
$\nabla H \gets \alpha \cdot \nabla_c + \beta \cdot \nabla_e + \gamma \cdot \delta V$\;
\textbf{Return} $\nabla H$\;
\end{algorithm}
}

\subsection{Hyperparameter Reference}

Table~\ref{tab:hyperparameters} summarizes all default hyperparameters used in the standard CL implementation. Tables~\ref{tab:sine_hyperparams} and~\ref{tab:mnist_hyperparams} provide dataset-specific configurations.

{\small
\begin{table}[h]
\centering
\caption{Default Hyperparameters}
\label{tab:hyperparameters}
\begin{tabular}{lll}
\hline
\textbf{Parameter} & \textbf{Default} & \textbf{Description} \\
\hline
\multicolumn{3}{l}{\textit{Gradient Computation}} \\
$\alpha$ & 0.4 & Current task gradient weight \\
$\beta$ & 0.4 & Experience replay gradient weight \\
$\gamma$ & 0.1 & Regularization gradient weight \\
$\sigma_x^2$ & $10^{-4}$ & Input perturbation variance \\
$\sigma_{\weight}^2$ & $10^{-8}$ & Parameter perturbation variance \\
\hline
\multicolumn{3}{l}{\textit{Optimization}} \\
$\eta_0$ & $10^{-4}$ & Base learning rate \\
$\eta_{\min}$ & $10^{-6}$ & Minimum learning rate \\
Optimizer & AdamW & Default optimizer \\
Gradient clip & 1.0 & Maximum gradient norm \\
LR schedule & Cosine & Learning rate decay (C2--C4) \\
\hline
\multicolumn{3}{l}{\textit{Task Warmup (C2--C4)}} \\
$N_{\text{warmup}}$ & 25 & Warmup epochs per task \\
LR factor & 0.1 & Warmup LR multiplier \\
\hline
\multicolumn{3}{l}{\textit{Experience Replay}} \\
Buffer size & 200,000 & Maximum samples \\
Recent quota & 10\% & From task $t-1$ \\
Older quota & 80\% & From tasks $0$ to $t-2$ \\
Random quota & 10\% & Uniform random \\
\hline
\multicolumn{3}{l}{\textit{AWB Pipeline (C4)}} \\
$N_{\text{prelim}}$ & 1--2 & Preliminary training epochs \\
$N_{\text{AB}}$ & 500 & A/B training epochs \\
$\eta_{\text{AB}}$ & $10^{-3}$ & A/B training learning rate \\
$\theta_{\text{loss}}$ & 1.1 & Loss ratio threshold for arch change \\
Search step & 16 & Dimension search step \\
\hline
\end{tabular}
\end{table}
}

{\small
\begin{table}[h]
\centering
\caption{Sine Regression Hyperparameters}
\label{tab:sine_hyperparams}
\begin{tabular}{lll}
\hline
\textbf{Parameter} & \textbf{Value} & \textbf{Description} \\
\hline
\multicolumn{3}{l}{\textit{Network Architecture}} \\
Network type & FCNN & Fully-connected neural network \\
Layers & 4 & Number of layers \\
Hidden size & 64 & Neurons per hidden layer \\
Activation & ReLU & Hidden layer activation \\
\hline
\multicolumn{3}{l}{\textit{Training}} \\
Tasks & 10 & Number of continual learning tasks \\
Epochs/task & 500 & Training epochs per task \\
Batch size & 1024 & Mini-batch size \\
Learning rate & $10^{-4}$ & Base learning rate \\
Optimizer & AdamW & Optimizer with weight decay \\
\hline
\multicolumn{3}{l}{\textit{Dataset}} \\
Input domain & $[-90, 90]$ & Uniform sampling domain for $x$ \\
Task variation & Amplitude, phase & How tasks differ \\
Train/test split & 80\%/20\% & Data partition \\
\hline
\end{tabular}
\end{table}
}

{\small
\begin{table}[h]
\centering
\caption{MNIST Classification Hyperparameters}
\label{tab:mnist_hyperparams}
\begin{tabular}{lll}
\hline
\textbf{Parameter} & \textbf{Value} & \textbf{Description} \\
\hline
\multicolumn{3}{l}{\textit{Network Architecture}} \\
Network type & CNN & Convolutional neural network \\
Conv layers & 2 & Number of convolutional layers \\
Filter size & 3 & Convolutional kernel size \\
Output channels & 3 & Channels per conv layer \\
Pool size & $2 \times 2$ & Max pooling kernel \\
FF hidden & [512, 64] & Feedforward hidden layer sizes \\
Activation & ReLU & Hidden layer activation \\
\hline
\multicolumn{3}{l}{\textit{Training}} \\
Tasks & 2 & Number of continual learning tasks \\
Epochs/task & 200 & Training epochs per task \\
Batch size & 1024 & Mini-batch size \\
Learning rate & $10^{-4}$ & Base learning rate \\
Optimizer & AdamW & Optimizer with weight decay \\
\hline
\multicolumn{3}{l}{\textit{Dataset}} \\
Input size & $28 \times 28$ & MNIST image dimensions \\
Task 0 & Digits 0--4 & First task classes \\
Task 1 & Digits 5--9 & Second task classes \\
Train/test split & 80\%/20\% & Data partition \\
\hline
\end{tabular}
\end{table}
}

\subsection{Implementation Notes}

\subsubsection{Gradient Normalization}

The $\nabla_{\weight} \delta V$ component is normalized by task count:
\begin{equation}
    \text{dV\_norm} = \frac{\|\nabla_{\weight} \delta V\|_2}{t + 1}
\end{equation}
This prevents the regularization term from dominating as more tasks are learned.

\subsubsection{Learning Rate Schedules}

The framework supports multiple LR schedules: constant, step, exponential, cosine, and linear. Default is cosine annealing with warm restarts.

\subsubsection{JAX Implementation}

All gradient computations are JIT-compiled using JAX with 8 variants for different problem types (regression/classification, standard/AWB, vector/graph).

\subsubsection{Model Partitioning}

Equinox models are partitioned for selective training: (1) standard training (all weights), (2) A/B training (freeze W), (3) V training (freeze A, B).
